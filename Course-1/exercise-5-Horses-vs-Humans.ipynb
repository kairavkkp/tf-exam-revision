{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import random\n",
    "from PIL import Image\n",
    "from numba import cuda\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/horses-vs-humans/'\n",
    "train_dir = '../data/horses-vs-humans/train/'\n",
    "valid_dir = '../data/horses-vs-humans/validation/'\n",
    "train_horses_dir = '../data/horses-vs-humans/train/horses/'\n",
    "train_humans_dir = '../data/horses-vs-humans/train/humans/'\n",
    "valid_horses_dir = '../data/horses-vs-humans/validation/horses/'\n",
    "valid_humans_dir = '../data/horses-vs-humans/validation/humans/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale= 1 / 255.0,\n",
    "                                  vertical_flip = True,\n",
    "                                  rotation_range=40,\n",
    "                                  shear_range = 0.2,width_shift_range=0.2,zoom_range=0.2,fill_mode='nearest')\n",
    "valid_datagen = ImageDataGenerator(rescale = 1 / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   target_size=(150,150),\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   class_mode='binary')\n",
    "valid_generator = valid_datagen.flow_from_directory(valid_dir,\n",
    "                                                   target_size=(150,150),\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(150,150,3)),   #148x148\n",
    "    tf.keras.layers.MaxPooling2D(2,2),                                            #74x74\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),                           #72x72\n",
    "    tf.keras.layers.MaxPooling2D(2,2),                                            #36x36\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),                           #34x34\n",
    "    tf.keras.layers.MaxPooling2D(2,2),                                            #17x17\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),                           #15x15\n",
    "    tf.keras.layers.MaxPooling2D(2,2),                                            #7x7\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 863,841\n",
      "Trainable params: 863,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "model.compile(loss='binary_crossentropy',optimizer = 'adam',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch,logs):\n",
    "        if logs.get('acc')>0.99:\n",
    "            print(\"Reached 99% accuracy so cancelling training.\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = MyCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-31b8b47d9a8e>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/20\n",
      "65/64 [==============================] - 13s 203ms/step - loss: 0.6965 - acc: 0.5180 - val_loss: 0.6337 - val_acc: 0.6250\n",
      "Epoch 2/20\n",
      "65/64 [==============================] - 13s 202ms/step - loss: 0.5986 - acc: 0.6981 - val_loss: 0.8581 - val_acc: 0.6797\n",
      "Epoch 3/20\n",
      "65/64 [==============================] - 14s 213ms/step - loss: 0.4419 - acc: 0.7877 - val_loss: 0.8194 - val_acc: 0.7734\n",
      "Epoch 4/20\n",
      "65/64 [==============================] - 14s 222ms/step - loss: 0.3710 - acc: 0.8257 - val_loss: 1.3828 - val_acc: 0.7070\n",
      "Epoch 5/20\n",
      "65/64 [==============================] - 14s 210ms/step - loss: 0.2779 - acc: 0.8744 - val_loss: 1.7000 - val_acc: 0.6953\n",
      "Epoch 6/20\n",
      "65/64 [==============================] - 15s 225ms/step - loss: 0.2325 - acc: 0.9133 - val_loss: 3.0747 - val_acc: 0.7109\n",
      "Epoch 7/20\n",
      "65/64 [==============================] - 18s 277ms/step - loss: 0.2447 - acc: 0.9114 - val_loss: 1.5648 - val_acc: 0.7578\n",
      "Epoch 8/20\n",
      "65/64 [==============================] - 13s 205ms/step - loss: 0.2338 - acc: 0.9163 - val_loss: 1.1640 - val_acc: 0.8164\n",
      "Epoch 9/20\n",
      "65/64 [==============================] - 14s 222ms/step - loss: 0.1617 - acc: 0.9396 - val_loss: 1.7349 - val_acc: 0.8047\n",
      "Epoch 10/20\n",
      "65/64 [==============================] - 16s 252ms/step - loss: 0.1412 - acc: 0.9464 - val_loss: 2.0510 - val_acc: 0.7422\n",
      "Epoch 11/20\n",
      "65/64 [==============================] - 17s 267ms/step - loss: 0.1575 - acc: 0.9426 - val_loss: 1.7084 - val_acc: 0.7734\n",
      "Epoch 12/20\n",
      "65/64 [==============================] - 18s 273ms/step - loss: 0.1259 - acc: 0.9445 - val_loss: 3.1824 - val_acc: 0.7148\n",
      "Epoch 13/20\n",
      "65/64 [==============================] - 18s 273ms/step - loss: 0.1278 - acc: 0.9406 - val_loss: 2.3887 - val_acc: 0.7734\n",
      "Epoch 14/20\n",
      "65/64 [==============================] - 15s 224ms/step - loss: 0.1097 - acc: 0.9572 - val_loss: 2.3876 - val_acc: 0.7344\n",
      "Epoch 15/20\n",
      "65/64 [==============================] - 14s 221ms/step - loss: 0.1202 - acc: 0.9562 - val_loss: 1.6539 - val_acc: 0.7773\n",
      "Epoch 16/20\n",
      "65/64 [==============================] - 15s 224ms/step - loss: 0.1092 - acc: 0.9620 - val_loss: 1.4155 - val_acc: 0.8477\n",
      "Epoch 17/20\n",
      "65/64 [==============================] - 14s 221ms/step - loss: 0.1298 - acc: 0.9542 - val_loss: 2.0823 - val_acc: 0.7656\n",
      "Epoch 18/20\n",
      "65/64 [==============================] - 14s 218ms/step - loss: 0.1017 - acc: 0.9669 - val_loss: 1.9844 - val_acc: 0.7539\n",
      "Epoch 19/20\n",
      "65/64 [==============================] - 15s 230ms/step - loss: 0.0767 - acc: 0.9679 - val_loss: 2.1127 - val_acc: 0.7812\n",
      "Epoch 20/20\n",
      "65/64 [==============================] - 14s 218ms/step - loss: 0.1101 - acc: 0.9649 - val_loss: 2.6875 - val_acc: 0.7617\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              validation_data=valid_generator,\n",
    "                              steps_per_epoch=1027/batch_size,\n",
    "                              epochs = 20,\n",
    "                              validation_steps=256/batch_size,\n",
    "                              shuffle=True,\n",
    "                              verbose=1,\n",
    "                             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n",
      "horse1.jpeg is a horse\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "path = '../data/horses-vs-humans/test/horse1.jpeg'\n",
    "img = image.load_img(path, target_size=(150, 150))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "classes = model.predict(images, batch_size=10)\n",
    "print(classes[0])\n",
    "if classes[0]>0.5:\n",
    "    print(path.split('/')[-1] + \" is a human\")\n",
    "else:\n",
    "    print(path.split('/')[-1] + \" is a horse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
